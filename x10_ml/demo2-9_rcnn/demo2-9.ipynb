{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # transforms.Grayscale(3),\n",
    "    # transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # 归一化到(0,1) 分布到(-1,1)\n",
    "])\n",
    "dataset1 = torchvision.datasets.MNIST(root=\"../../data\", train=True, download=True, transform=transform)\n",
    "dataset2 = torchvision.datasets.MNIST(root=\"../../data\", train=False, download=False, transform=transform)\n",
    "# DataLoader num_workers 不要设置, cpu: num_workers=2\n",
    "train_loader: DataLoader = torch.utils.data.DataLoader(dataset1, batch_size=64, shuffle=True)\n",
    "test_loader: DataLoader = torch.utils.data.DataLoader(dataset2, batch_size=1000, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def train(model: nn.Module, device, train_loader, optimizer: torch.optim.Optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            # Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.142410\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "                loss.item()))\n",
    "\n",
    "\n",
    "def test(model: nn.Module, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdims=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # Test set: Average loss: 0.0483, Accuracy: 9849/10000 (98%)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss,\n",
    "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): ConvTranspose2d(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(pretrained=False, num_classes=10)\n",
    "model.features[0] = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "model.features[2] = nn.ConvTranspose2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), bias=False)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=1)\n",
    "\n",
    "scheduler = StepLR(optimizer=optimizer, step_size=1, gamma=.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000123\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: -17149345363674402218049536.000000\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: -51548153488640256031850496.000000\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: -85474095470177629985832960.000000\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: -117233679497814664762359808.000000\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: -151023493731460099080192000.000000\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: -188580529709954608593371136.000000\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: -225017092006667926231842816.000000\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: -257203819616703742530813952.000000\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: -287300734037373077436760064.000000\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: -326992519473797624810700800.000000\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: -355710558221701244442902528.000000\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: -393907198157463485239263232.000000\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: -433882915878670570031677440.000000\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: -454703423873273214168727552.000000\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: -491886341435208820265582592.000000\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: -517683190685087942722977792.000000\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: -544333755250698343229161472.000000\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: -593909416842280910616264704.000000\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: -621121869232376504064671744.000000\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: -676040851605837927591968768.000000\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: -692472104422053973598404608.000000\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: -729880404303082162996903936.000000\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: -748602742733252935314046976.000000\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: -776152586072456676461510656.000000\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: -852926385380733638684966912.000000\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: -835175304919531821679509504.000000\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: -896768319298861360981475328.000000\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: -928862185999230123397611520.000000\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: -958563731354167641483771904.000000\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: -990672134088866487026581504.000000\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: -1019723321034741301160968192.000000\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: -1062686452065197500418490368.000000\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: -1107345355384861671336968192.000000\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: -1128090416196202843407908864.000000\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: -1195761263812938205776314368.000000\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: -1196032947459655800052514816.000000\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: -1225240784156204555699224576.000000\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: -1264978538878860787275792384.000000\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: -1303963887804238553661046784.000000\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: -1322354258628058848887308288.000000\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: -1382728385945973955856695296.000000\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: -1418525104477746583987814400.000000\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: -1399676073809277574470172672.000000\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: -1458064888743003764656439296.000000\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: -1472410405100293619080757248.000000\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: -1515312071579496218112294912.000000\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: -1554974489799355419880062976.000000\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: -1616508105662767614425825280.000000\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: -1621908574457786822756925440.000000\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: -1667545376574286484425670656.000000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1 + 5):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}