{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T01:49:02.677589Z",
     "start_time": "2024-05-15T01:48:51.163903Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "# scp -i ~/Desktop/www/wolanx-note/__cicd__/ssh-106006/KEY-GIMC-BIGDATA-D.pem vb.ipynb root@10.231.9.124:/www/test/vb-test/\n",
    "import h5py\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from h5py import File\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch import nn, optim\n",
    "from torch import utils\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from torchvision import transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e1d395755fd6ef2d",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T01:49:05.070581Z",
     "start_time": "2024-05-15T01:49:05.044728Z"
    }
   },
   "source": [
    "# f: File = h5py.File(\"/www/test/vb-test/data/fault-data/fault_data.h5\", \"r\")\n",
    "f: File = h5py.File(\"./data/fault-data-2280.h5\", \"r\")\n",
    "\n",
    "codeArr = f['label']\n",
    "waveArr = f['wave_data']\n",
    "fftAbsArr = f['wave_fft_abs']\n",
    "dataSize = len(codeArr)\n",
    "\n",
    "# codeArr[:] > 4\n",
    "\n",
    "waveWeb = waveArr[1]\n",
    "waveWeb = np.array(waveWeb)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1cd589628aa68b7c",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T01:49:06.135724Z",
     "start_time": "2024-05-15T01:49:05.928068Z"
    }
   },
   "source": [
    "cnt = len(waveWeb)\n",
    "\n",
    "fftArr = np.fft.fft(waveWeb)\n",
    "hzArr = np.fft.fftfreq(len(fftArr), 1 / 5120)\n",
    "\n",
    "hzArr = hzArr[:cnt // 2]\n",
    "fftArr = fftArr[:cnt // 2]\n",
    "\n",
    "# 绘制频域数据\n",
    "plt.figure(figsize=(20, 3))\n",
    "# plt.plot(waveWeb)\n",
    "plt.plot(hzArr, np.abs(fftArr))\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('nm/s')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "15e7b778fcba8311",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T01:49:07.389757Z",
     "start_time": "2024-05-15T01:49:07.136927Z"
    }
   },
   "source": [
    "# 频谱图\n",
    "hzArr, times, sxx = signal.spectrogram(waveArr[219], 5120)\n",
    "\n",
    "print(sxx.shape)\n",
    "print(sxx)\n",
    "\n",
    "plt.pcolormesh(times, hzArr, 10 * np.log10(sxx))\n",
    "plt.title('Spectrogram of the Waveform')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.colorbar(label='Power Spectral Density [dB/Hz]')\n",
    "plt.show()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T01:49:08.397964Z",
     "start_time": "2024-05-15T01:49:08.387403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 画图 tool\n",
    "def drawWave(ids: list = [], df=None, log=False):\n",
    "    fig, ax = plt.subplots(nrows=len(ids), ncols=2, figsize=(20, 10), dpi=100)\n",
    "    for i, idx in enumerate(ids):\n",
    "        y, y_, ok = df.loc[i]['y'], df.loc[i]['y_'], df.loc[i]['ok']\n",
    "        # ax[i, 0].set_ylim(-2.5, 2.5)\n",
    "        ax[i, 0].set_ylabel(f\"{idx}    \", rotation=0, fontdict={'size': 16})\n",
    "        ax[i, 0].plot(waveArr[idx])\n",
    "\n",
    "        color_ = '#0f0' if ok else '#f00'\n",
    "        ax[i, 1].set_title(f\"{y} - {y_}\", fontdict={'size': 16, 'color': color_}, x=0.5, y=0.5)\n",
    "        # ax[i, 1].set_ylim(0, max(fftAbsArr[idx]))\n",
    "        if log:\n",
    "            ax[i, 1].set_yscale(\"symlog\")\n",
    "        ax[i, 1].plot(fftAbsArr[idx])\n",
    "\n",
    "\n",
    "def drawHis(ids: list = [], df=None, log=False):\n",
    "    nrows, ncols = len(ids) // 5, 5\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 20), dpi=100)\n",
    "    for i, id_ in enumerate(ids):\n",
    "        y, y_, ok = df.loc[i]['y'], df.loc[i]['y_'], df.loc[i]['ok']\n",
    "        hzArr, times, Sxx = signal.spectrogram(np.array(waveArr[id_], dtype=np.float32), 5120)\n",
    "        ax[i // 5, i % 5].set_ylabel(f\"{id_}\", rotation=0, fontdict={'size': 16}, x=1, y=0.5)\n",
    "        color_ = '#0f0' if ok else '#f00'\n",
    "        ax[i // 5, i % 5].set_title(f\"{y} - {y_}\", fontdict={'size': 24, 'color': color_}, x=0.5, y=0.5)\n",
    "        ax[i // 5, i % 5].pcolormesh(times, hzArr, 10 * np.log10(Sxx))"
   ],
   "id": "81ef40a2d18849af",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c3bbd5e0082289a3",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T01:54:15.329348Z",
     "start_time": "2024-05-15T01:54:14.230773Z"
    }
   },
   "source": [
    "class MyDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, trainSet, batchSize: int, transform=None):\n",
    "        super().__init__()\n",
    "        self.batchSize = batchSize\n",
    "        self.transform = transform\n",
    "        self.trainSet, self.validSet, self.testsSet = utils.data.random_split(trainSet, [0.7, 0.2, 0.1])\n",
    "        print('dataset num', len(self.trainSet), len(self.validSet), len(self.testsSet))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.trainSet, batch_size=self.batchSize, shuffle=False)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.validSet, batch_size=self.batchSize, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.testsSet, batch_size=self.batchSize, shuffle=False)\n",
    "\n",
    "    def apply_transform(self, x):\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def min_max_scale(x):\n",
    "    min_val = torch.min(x)\n",
    "    max_val = torch.max(x)\n",
    "    scaled_data = (x - min_val) / (max_val - min_val)\n",
    "    return scaled_data\n",
    "\n",
    "\n",
    "# 定义 torchvision.transforms 的组合\n",
    "custom_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: min_max_scale(x)),\n",
    "])\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "fftAbsArr2 = scaler.fit_transform(fftAbsArr)\n",
    "\n",
    "sxxArr = []\n",
    "for waveOne in waveArr:\n",
    "    _, _, sxx = signal.spectrogram(waveOne, 5120)\n",
    "    sxxArr.append(sxx)\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(sxxArr), torch.tensor(codeArr, dtype=torch.int64))\n",
    "dm = MyDataModule(dataset, batchSize=128, transform=None)  # custom_transform"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T01:55:13.221748Z",
     "start_time": "2024-05-15T01:54:59.058287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyModel(pl.LightningModule):\n",
    "    def __init__(self, lr: float):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(\"lr\")\n",
    "\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=6)\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=6)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=.25)\n",
    "        self.fc1 = nn.Linear(18576, 256)\n",
    "        self.fc2 = nn.Linear(256, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 1, 129, 9)  # [64, 1, 1024]\n",
    "        x = self.conv1(x)  # [64, 3, 1024]\n",
    "        x = self.relu(x)\n",
    "        # x = self.pool(x)  # [64, 3, 512]\n",
    "        x = self.conv2(x)  # [64, 3, 512]\n",
    "        x = self.relu(x)\n",
    "        # x = self.pool(x)  # [64, 3, 256]\n",
    "        x = torch.flatten(x, 1)  # [64, 129, 9] => [64, 1161]\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.fc2(x)  # batch, 6\n",
    "\n",
    "        # x = F.sigmoid(x)  # batch, 6\n",
    "        # x = F.sigmoid(x, dim=-1)  # batch, 6\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        hparams = self.hparams\n",
    "        optimizer = optim.Adam(self.parameters(), lr=hparams.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels) # , reduction='sum'\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        _, y_ = torch.max(outputs, 1)\n",
    "        # print('yt.shape', labels.shape, labels)\n",
    "        # print('y_.shape', y_.shape, y_)\n",
    "        self.val_acc.update(y_, labels)\n",
    "        self.val_f1.update(y_, labels)\n",
    "\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        print(\"{} val acc={:.3f} f1={:.3f}\".format(self.current_epoch, self.val_acc.compute(), self.val_f1.compute()))\n",
    "        self.val_acc.reset()\n",
    "        self.val_f1.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        _, y_ = torch.max(outputs, 1)\n",
    "        print('yt.shape', labels.shape, labels)\n",
    "        print('y_.shape', y_.shape, y_)\n",
    "        self.val_acc.update(y_, labels)\n",
    "        self.val_f1.update(y_, labels)\n",
    "\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        print(\"{} test acc={:.3f} f1={:.3f}\".format(self.current_epoch, self.val_acc.compute(), self.val_f1.compute()))\n",
    "        self.val_acc.reset()\n",
    "        self.val_f1.reset()\n",
    "\n",
    "\n",
    "model = MyModel(lr=0.001)\n",
    "\n",
    "logger = None\n",
    "trainer = pl.Trainer(logger=logger, max_epochs=10, enable_progress_bar=True, enable_checkpointing=False)\n",
    "trainer.fit(model, datamodule=dm)\n",
    "trainer.test(model, datamodule=dm)"
   ],
   "id": "4bf5ba3346954d9",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T01:56:00.124086Z",
     "start_time": "2024-05-15T01:56:00.053836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "BaseplateUnbalance: 1\n",
    "Misaligned: 2\n",
    "Bearing: 3\n",
    "ImpellerUnbalance: 4\n",
    "Cavitation: 5\n",
    "\"\"\"\n",
    "model.eval()\n",
    "\n",
    "_page = 0\n",
    "# ids = range(10 * _page, 10 * _page + 25, 1)\n",
    "ids = [random.randint(1, 2000) for i in range(20)]\n",
    "\n",
    "df = pd.DataFrame(columns=['id', \"y\", \"y_\", 'ratio'])\n",
    "for i, id_ in enumerate(ids):\n",
    "    x = torch.tensor([[fftAbsArr[id_]]], dtype=torch.float32)\n",
    "    ret = model(x)\n",
    "    # print(ret[0])\n",
    "\n",
    "    y = codeArr[id_]\n",
    "    # p_, y_ = torch.max(ret[0], -1)\n",
    "    p_, y_ = torch.max(torch.softmax(ret[0], dim=-1), dim=-1)\n",
    "    df.loc[len(df)] = {'id': id_, 'y': y, \"y_\": y_.item(), 'ratio': p_.item()}\n",
    "\n",
    "df[\"ok\"] = df[\"y\"] == df[\"y_\"]\n",
    "print(df)\n",
    "\n",
    "# drawWave(ids=ids, df=df, log=False)\n",
    "# drawHis(ids=ids, df=df, log=True)"
   ],
   "id": "63cd6f6a55c9f904",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e1b553cd67b06704",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T01:56:09.246756Z",
     "start_time": "2024-05-15T01:56:00.639531Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import onnxruntime as ort\n",
    "\n",
    "sess = ort.InferenceSession(\"vb-2023-11-22.onnx\")\n",
    "\n",
    "\n",
    "def get_score(dataSet, label: str = ''):\n",
    "    y_pred = []\n",
    "    for one in dataSet:\n",
    "        # print(dm.apply_transform(one[0]))\n",
    "        y_pred.append(torch.argmax(model(one[0].unsqueeze(0)), dim=1).item())\n",
    "\n",
    "    acc = accuracy_score(dataSet[:][1], y_pred)\n",
    "    f1 = f1_score(dataSet[:][1], y_pred, average='macro')\n",
    "    print('acc {:.3f} , f1 {:.3f} {}'.format(acc, f1, label))\n",
    "\n",
    "\n",
    "def get_onnx(dataSet, label: str = ''):\n",
    "    y_pred = []\n",
    "    for one in dataSet:\n",
    "        result = sess.run(None, {\"input\": np.array(one[0], np.float32)})[0]\n",
    "        y_pred.append(np.argmax(result))\n",
    "\n",
    "    arr = dataSet[:][1].numpy().tolist()\n",
    "    # print(arr)\n",
    "    # print(y_pred)\n",
    "    acc = accuracy_score(arr, y_pred)\n",
    "    f1 = f1_score(arr, y_pred, average='macro')\n",
    "    print('acc {:.3f} , f1 {:.3f} {}'.format(acc, f1, label))\n",
    "\n",
    "\n",
    "get_score(dm.trainSet, 'train')\n",
    "get_score(dm.validSet, 'valid')\n",
    "get_score(dm.testsSet, 'tests')\n",
    "print('------ model')\n",
    "get_score(dataset)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# print(dataset[:10])\n",
    "\n",
    "get_onnx(dm.trainSet, 'train')\n",
    "get_onnx(dm.validSet, 'valid')\n",
    "get_onnx(dm.testsSet, 'tests')\n",
    "print('------ onnx')\n",
    "get_onnx(dataset)\n",
    "# dm.trainSet[1][0].numpy()"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T08:52:33.502484Z",
     "start_time": "2024-05-14T08:52:33.400442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.randn(1024).unsqueeze(0)  # sample\n",
    "print(inputs.shape)\n",
    "\n",
    "model.to_onnx(\n",
    "    'vb-2024-05-14.onnx',\n",
    "    input_sample=inputs,\n",
    "    export_params=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
    ")"
   ],
   "id": "3ca098964e6e4cae",
   "execution_count": 99,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "b6bec0aa69d79834",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
